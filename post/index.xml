<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Yongjun&#39;s blog</title>
    <link>https://elwhyjay.github.io/post/</link>
    <description>Recent content in Posts on Yongjun&#39;s blog</description>
    <generator>Hugo</generator>
    <language>ko-kr</language>
    <lastBuildDate>Sat, 07 Feb 2026 00:35:33 +0900</lastBuildDate>
    <atom:link href="https://elwhyjay.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>FFT on GPU</title>
      <link>https://elwhyjay.github.io/post/fft/</link>
      <pubDate>Sat, 07 Feb 2026 00:35:33 +0900</pubDate>
      <guid>https://elwhyjay.github.io/post/fft/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&lt;p&gt;이 포스트에서 다룰것은 Fast fourier Transform이다. 이 알고리즘에대해서는 PS(Competitve programming) 하는 사람들은 익히 알것이다. 실제로 검색을해보면 알고리즘에 대해서는 상세히 알수가있다. 그렇기때문에 알고리즘을 톺아보기보다 GPU위에서 FFT를 구현하는것에대해 초점을 맞춰 글을 작성할 예정이다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;background&#34;&gt;Background&lt;/h1&gt;&#xA;&lt;h2 id=&#34;fourier-transform&#34;&gt;Fourier Transform&lt;/h2&gt;&#xA;&lt;p&gt;Fourier Transform(푸리에 변환)은 신호를 주파수 성분으로 분해하는 수학적 기법이다. 이는 시간 도메인에서 표현된 신호를 주파수 도메인으로 변환하여, 신호의 주파수 특성을 분석하고 처리하는 데 사용된다. 푸리에 변환은 다양한 분야에서 활용되며, 특히 신호 처리, 이미지 처리, 음성 인식, 통신 시스템 등에서 중요한 역할을 한다. 정의는 이러한데 그렇다면 푸리에 변환은 이런 특정 도메인이 아니면 전혀 쓸모가 없는것일까? 익히 알려져있듯 이러한 도메인이아니라 일반적인 연산 영역에서도 푸리에 변환은 유용하게 사용될 수 있다. 이를 중점으로 살펴보자.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data_format</title>
      <link>https://elwhyjay.github.io/post/data_format/</link>
      <pubDate>Sun, 28 Dec 2025 21:59:14 +0900</pubDate>
      <guid>https://elwhyjay.github.io/post/data_format/</guid>
      <description>&lt;h1 id=&#34;현대-ai-데이터-타입-ml-엔지니어와-cuda-개발자를-위한-기술-심층-분석&#34;&gt;현대 AI 데이터 타입: ML 엔지니어와 CUDA 개발자를 위한 기술 심층 분석&lt;/h1&gt;&#xA;&lt;p&gt;저정밀도 수치 포맷은 효율적인 AI 추론의 핵심이 되었으며, &lt;strong&gt;FP8&lt;/strong&gt;은 Hopper GPU에서 &lt;strong&gt;2배의 처리량 증가&lt;/strong&gt;를 제공하면서 FP16에 가까운 정확도를 유지하고, &lt;strong&gt;INT4 가중치 전용(weight-only) 양자화&lt;/strong&gt;는 70B 파라미터 모델을 단일 48GB GPU에서 실행할 수 있게 해준다. 이 보고서는 15개 이상의 데이터 포맷에 대한 수학적 명세, 4세대 NVIDIA 아키텍처 전반에 걸친 하드웨어별 성능 특성, 그리고 양자화 알고리즘에 대한 정량적 분석을 제공한다. 이는 프로덕션 LLM 시스템을 배포하는 데 필수적인 지식이다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Int4 to FP16 dequantization optimization</title>
      <link>https://elwhyjay.github.io/post/int8tofloat16/</link>
      <pubDate>Tue, 02 Dec 2025 17:44:26 +0900</pubDate>
      <guid>https://elwhyjay.github.io/post/int8tofloat16/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Quantization은 현재 LLM 분야에서 중요한 기술로 자리잡았다. 특히 추론을 최적화하는데 있어서 가중치를 int4, int8 등의 저정밀도 정수형으로 양자화하는 기법이 널리 사용되고 있다. 이 기법을 통해 모델의 메모리 사용량을 줄이고, 메모리 대역폭 요구사항을 낮추며, 하드웨어 가속기의 연산 처리량을 극대화할 수 있다. 하지만 양자화 기술은 만능이 아니고 많은 경우에 최적화가 요구될 수 있다.&lt;/p&gt;&#xA;&lt;p&gt;이 글에서는 QServe에서 소개된 &lt;a href=&#34;https://arxiv.org/abs/2211.10017&#34;&gt;Kim et al.&lt;/a&gt; 의 논문에서 제시된 int4 양자화된 KV cache를 FP16 활성화 값으로 역양자화하는 비트 최적화 기법에 대해 살펴본다. 역양자화는 때로 과도한 연산량을 요구할 수 있기 때문에, 이를 효율적으로 처리하는 것이 중요하다. 이 최적화 기법은 computing resource를 절약하는 효과적인 방법중 하나로 이해하고 비슷한시나리오에서 사용가능할것 같다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gpu_architec</title>
      <link>https://elwhyjay.github.io/post/gpu_architec/</link>
      <pubDate>Wed, 06 Aug 2025 12:22:45 +0900</pubDate>
      <guid>https://elwhyjay.github.io/post/gpu_architec/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;gpu programming을 하기위해서는 gpu architecture에 대한 이해가 필요하다. gpu가 무엇인지는 현재에와서는 모르는 사람이 없을것이다.&#xA;때문에 gpu에 대한 소개는 생략하고 gpu architecture를 곧바로 살펴보자&lt;/p&gt;&#xA;&lt;h2 id=&#34;gpu-hardware-architecture&#34;&gt;GPU Hardware Architecture&lt;/h2&gt;&#xA;&lt;p&gt;gpu architecture는 크게 다음과 같은 요소로 구성된다.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Streaming Multiprocessors (SMs)&lt;/strong&gt;: GPU의 핵심 컴퓨팅 유닛으로, 병렬 처리를 수행한다. 각 SM은 여러 개의 CUDA 코어를 포함하고 있으며, 동시에 여러 스레드를 실행할 수 있다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;HBM (High Bandwidth Memory)&lt;/strong&gt;: GPU의 글로벌 메모리로, 데이터 전송 속도가 매우 빠르다. HBM은 GPU와 CPU 간의 데이터 전송을 최적화하여 높은 성능을 제공한다. DRAM을 적층해 만든 구조로 CPU에서 DRAM의 역할과 유사하다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;L2 Cache&lt;/strong&gt;: GPU의 L2 캐시는 데이터 접근 속도를 높이기 위해 사용된다. L2 캐시는 GPU와 HBM 사이의 중간 캐시 역할을 하며, 자주 사용되는 데이터를 저장하여 빠른 접근을 가능하게 한다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;NVLink&lt;/strong&gt;: 다른 GPU와의 연결을 위한 인터페이스로 , 다중 GPU 시스템에서 높은 대역폭을 제공한다. NVLink는 GPU 간의 데이터 전송 속도를 향상시켜, 병렬 처리 성능을 극대화한다.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;streaming-multiprocessors-sms&#34;&gt;Streaming Multiprocessors (SMs)&lt;/h3&gt;&#xA;&lt;p&gt;SMs는 GPU의 핵심 컴퓨팅 유닛으로, 병렬 처리를 수행한다. 각 SM은 다음과 같은 구성 요소로 이루어져 있다:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Loss Function in information geometry</title>
      <link>https://elwhyjay.github.io/post/loss-function/</link>
      <pubDate>Wed, 11 Jun 2025 13:41:05 +0900</pubDate>
      <guid>https://elwhyjay.github.io/post/loss-function/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;머신러닝에서 loss function, 즉 손실함수는 모델의 예측값과 실제값 사이의 차이를 측정하는 역할을 한다. 이 함수는 모델의 성능을 평가하고, 최적화 과정에서 모델의 파라미터를 조정하는 데 사용된다. 정보기하학에서는 손실함수를 기하학적 관점에서 분석할 수 있다. 이 글에서는 정보기하학에서 손실함수의 역할과 그 기하학적 해석에 대해 살펴본다.&lt;/p&gt;&#xA;&lt;h2 id=&#34;loss-function-in-information-geometry&#34;&gt;Loss Function in Information Geometry&lt;/h2&gt;</description>
    </item>
    <item>
      <title>cuda basic operation</title>
      <link>https://elwhyjay.github.io/post/cuda-basic-operation/</link>
      <pubDate>Wed, 05 Mar 2025 15:22:43 +0900</pubDate>
      <guid>https://elwhyjay.github.io/post/cuda-basic-operation/</guid>
      <description>&lt;h1 id=&#34;cuda-기본연산&#34;&gt;CUDA 기본연산&lt;/h1&gt;&#xA;&lt;h2 id=&#34;기본적인-함수설명&#34;&gt;기본적인 함수설명&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;cudamalloc&lt;/code&gt;은 device memory를 할당하는 함수이다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;cudaMemcpy&lt;/code&gt;은 host와 device간의 데이터를 복사하는 함수이다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;cudaFree&lt;/code&gt;는 device memory를 해제하는 함수이다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;cudaDeviceSynchronize&lt;/code&gt;는 device에서 실행중인 모든 kernel이 종료될때까지 기다리는 함수이다.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;덧셈연산&#34;&gt;덧셈연산&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;cuda_runtime.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;__global__ &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vector_add&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; A, &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; B, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; C, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; N) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; threadIdx.x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; blockIdx.x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blockDim.x;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; stride &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; blockDim.x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; gridDim.x;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;idx;i&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;N;i&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;stride) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        C[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[i] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; B[i];&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;solve&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; A, &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; B, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; C, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; N) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d_A, &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d_B, &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d_C;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Allocate device memory&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaMalloc&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;d_A, N &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;));&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaMalloc&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;d_B, N &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;));&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaMalloc&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;d_C, N &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;));&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Copy input data from host to device&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaMemcpy&lt;/span&gt;(d_A, A, N &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;), cudaMemcpyHostToDevice);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaMemcpy&lt;/span&gt;(d_B, B, N &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;), cudaMemcpyHostToDevice);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Calculate grid and block dimensions&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; threadsPerBlock &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; blocksPerGrid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (N &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threadsPerBlock &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; threadsPerBlock;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Launch the kernel&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    vector_add&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;blocksPerGrid, threadsPerBlock&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(d_A, d_B, d_C, N);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaDeviceSynchronize&lt;/span&gt;();&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Copy result back to host&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaMemcpy&lt;/span&gt;(C, d_C, N &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;), cudaMemcpyDeviceToHost);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Free device memory&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaFree&lt;/span&gt;(d_A);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaFree&lt;/span&gt;(d_B);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaFree&lt;/span&gt;(d_C);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;곱셈연산&#34;&gt;곱셈연산&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;cuda_runtime.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;__global__ &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;matrix_multiplication_kernel&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; A, &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; B, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; C, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; M, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; N, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; K) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; col &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; blockIdx.x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blockDim.x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threadIdx.x;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; row &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; blockIdx.y &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blockDim.y &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threadIdx.y;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt;(row &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; M &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; col &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; K) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; val &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;;i&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;N;i&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            val &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; A[(row&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;N) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; i]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;B[(K&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;i)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;col];&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        C[(row&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;K)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;col] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; val;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// A, B, C are device pointers (i.e. pointers to memory on the GPU)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// A,B,C 가 device pointer이므로 cudaMalloc과 cudaMemcpy는 생략한다.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;solve&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; A, &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; B, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; C, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; M, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; N, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; K) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    dim3 &lt;span style=&#34;color:#a6e22e&#34;&gt;threadsPerBlock&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    dim3 &lt;span style=&#34;color:#a6e22e&#34;&gt;blocksPerGrid&lt;/span&gt;((K &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threadsPerBlock.x &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; threadsPerBlock.x,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                       (M &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threadsPerBlock.y &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; threadsPerBlock.y);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    matrix_multiplication_kernel&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;blocksPerGrid, threadsPerBlock&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(A, B, C, M, N, K);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaDeviceSynchronize&lt;/span&gt;();&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A matrix의 크기가 MxN이고 B matrix의 크기가 NxK일때, C matrix의 크기는 MxK인 곱셈을 수행한다.&#xA;이 구현은 꽤 Naive한 구현이다. 이 구현에서 CUDA Kernel은 DRAM을 사용하여 각 thread가 A와 B의 행렬을 곱하는 방식으로 동작한다. 조금더 개선된 속도를 위해&#xA;shared memory를 사용하여 A와 B의 행렬을 곱하는 방식이 있다. 구현은 다음과 같다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Matryoshka Representation Learning Review</title>
      <link>https://elwhyjay.github.io/post/matryoshka-representation-learning-review/</link>
      <pubDate>Fri, 27 Sep 2024 00:00:29 +0900</pubDate>
      <guid>https://elwhyjay.github.io/post/matryoshka-representation-learning-review/</guid>
      <description>&lt;p&gt;blog도 개설한겸 논문한편을 리뷰해보고자 한다. 정말 오랜만에 작성하는 리뷰이다. 이 논문의 제목은&#xA;Matryoshka Representation Learning 으로 Neurips&#39;22 에 accept된 논문이다.&lt;/p&gt;&#xA;&lt;p&gt;학습된 representation (예를 들어 encoder로 embedding된 sentence 등)은 다양한 다운스트림 task에 활용된다. Bert 계열의 encoder의 embedding출력값이 768차원으로 고정되듯 각 다운스트림 task에서 고정된 표현은 부족하거나 과할 수 있다. 이 때 적절한 차원으로의 축소 역시 그 크기를 정하는데 많은 리소스를 사용해야만 한다. 이 논문은 마트료시카 표현 학습 방법(MRL)을 제시함으로써 인코더가 다양한 정보로 표현을 임베딩해 다운스트림 task에 적응하는 방법을 제시한다. MRL을 통해 학습된 표현은 단일모델로 학습된 동일한 차원의 표현만큼 잘 학습한다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>STS Project 회고</title>
      <link>https://elwhyjay.github.io/post/sts-project-%ED%9A%8C%EA%B3%A0/</link>
      <pubDate>Wed, 25 Sep 2024 01:15:36 +0900</pubDate>
      <guid>https://elwhyjay.github.io/post/sts-project-%ED%9A%8C%EA%B3%A0/</guid>
      <description>&lt;h2 id=&#34;프로젝트를-마치며&#34;&gt;프로젝트를 마치며&lt;/h2&gt;&#xA;&lt;p&gt;부스트캠프에서 첫 팀 프로젝트로 캐글형식의 대회를 진행했다. 회고를 쓴 시점에서 최종순위가 나온것은아니지만&#xA;대략적인 얼개는 나온것같다. 결론부터 말하면 중간정도의 성적이다. 애당초 시작할때 높은 순위가 목표도 아니었고&#xA;또 지속적으로 해온 대회라 데이터의 누적으로 순위가 사소한 차이로 갈렸기 때문에 큰 의미는 두지 않아도 될것 같다.&#xA;하지만 그렇다고 아쉬움이 없었던것은 아니다. 추석 연휴가 끼어있어서 상당히 길게 프로젝트를 진행했음에도 미숙하게 한점이&#xA;많은것같다. 이는 대체로 나의 잘못인데 밑에서 자세히 적도록 하겠다.&#xA;대회는 STS(sematical text similarity) 문제로 두 문장의 유사도를 점수로 나타내고 이를 피어슨 상관계수로 평가하는&#xA;형식이었다. 기본적으로 base 코드도 주어지기때문에 큰 틀은 여느 팀이나 비슷했다. 그래서 대회중에 색다른 시도를 몇가지&#xA;해보고자 했는데 그에대해 먼저 적어볼까 한다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hello_blog</title>
      <link>https://elwhyjay.github.io/post/hello_blog/</link>
      <pubDate>Tue, 24 Sep 2024 22:28:28 +0900</pubDate>
      <guid>https://elwhyjay.github.io/post/hello_blog/</guid>
      <description>&lt;h1 id=&#34;this-is-first-blog-post&#34;&gt;This is first blog post&lt;/h1&gt;</description>
    </item>
    <item>
      <title>공사장의 구석</title>
      <link>https://elwhyjay.github.io/post/game-of-life/</link>
      <pubDate>Tue, 24 Sep 2024 00:00:01 +0900</pubDate>
      <guid>https://elwhyjay.github.io/post/game-of-life/</guid>
      <description>&lt;div id=&#34;gol-controls&#34; style=&#34;margin-bottom: 8px; display: flex; gap: 8px; align-items: center;&#34;&gt;&#xA;    &lt;button id=&#34;gol-toggle&#34;&gt;Pause&lt;/button&gt;&#xA;    &lt;button id=&#34;gol-reset&#34;&gt;Reset&lt;/button&gt;&#xA;    &lt;span id=&#34;gol-count&#34; style=&#34;opacity: 0.6;&#34;&gt;alive: 0&lt;/span&gt;&#xA;    &lt;span id=&#34;gol-gen&#34; style=&#34;opacity: 0.6;&#34;&gt;gen: 0&lt;/span&gt;&#xA;&lt;/div&gt;&#xA;&lt;pre id=&#34;gol&#34; style=&#34;font-size: 10px; line-height: 1.1; letter-spacing: 1px; user-select: none;&#34;&gt;&lt;/pre&gt;&#xA;&lt;p style=&#34;opacity: 0.4; font-size: 0.85em;&#34;&gt;click to toggle cells&lt;/p&gt;&#xA;&lt;style&gt;&#xA;    #gol-controls button {&#xA;        font-family: inherit;&#xA;        font-size: inherit;&#xA;        background: transparent;&#xA;        color: inherit;&#xA;        border: 1px solid;&#xA;        padding: 2px 8px;&#xA;        cursor: pointer;&#xA;    }&#xA;&lt;/style&gt;&#xA;&lt;script&gt;&#xA;(function() {&#xA;    var W = 60, H = 30;&#xA;    var grid = [];&#xA;    var running = true;&#xA;    var generation = 0;&#xA;    var el = document.getElementById(&#39;gol&#39;);&#xA;    var countEl = document.getElementById(&#39;gol-count&#39;);&#xA;    var genEl = document.getElementById(&#39;gol-gen&#39;);&#xA;    var toggleBtn = document.getElementById(&#39;gol-toggle&#39;);&#xA;    var resetBtn = document.getElementById(&#39;gol-reset&#39;);&#xA;    var timer = null;&#xA;&#xA;    function init() {&#xA;        grid = [];&#xA;        generation = 0;&#xA;        for (var y = 0; y &lt; H; y++) {&#xA;            grid[y] = [];&#xA;            for (var x = 0; x &lt; W; x++) {&#xA;                grid[y][x] = Math.random() &lt; 0.3 ? 1 : 0;&#xA;            }&#xA;        }&#xA;    }&#xA;&#xA;    function countNeighbors(g, x, y) {&#xA;        var c = 0;&#xA;        for (var dy = -1; dy &lt;= 1; dy++) {&#xA;            for (var dx = -1; dx &lt;= 1; dx++) {&#xA;                if (dx === 0 &amp;&amp; dy === 0) continue;&#xA;                var ny = (y + dy + H) % H;&#xA;                var nx = (x + dx + W) % W;&#xA;                c += g[ny][nx];&#xA;            }&#xA;        }&#xA;        return c;&#xA;    }&#xA;&#xA;    function step() {&#xA;        var next = [];&#xA;        for (var y = 0; y &lt; H; y++) {&#xA;            next[y] = [];&#xA;            for (var x = 0; x &lt; W; x++) {&#xA;                var n = countNeighbors(grid, x, y);&#xA;                if (grid[y][x]) {&#xA;                    next[y][x] = (n === 2 || n === 3) ? 1 : 0;&#xA;                } else {&#xA;                    next[y][x] = (n === 3) ? 1 : 0;&#xA;                }&#xA;            }&#xA;        }&#xA;        grid = next;&#xA;        generation++;&#xA;    }&#xA;&#xA;    function render() {&#xA;        var alive = 0;&#xA;        var lines = [];&#xA;        for (var y = 0; y &lt; H; y++) {&#xA;            var row = &#39;&#39;;&#xA;            for (var x = 0; x &lt; W; x++) {&#xA;                if (grid[y][x]) {&#xA;                    row += &#39;#&#39;;&#xA;                    alive++;&#xA;                } else {&#xA;                    row += &#39;.&#39;;&#xA;                }&#xA;            }&#xA;            lines.push(row);&#xA;        }&#xA;        el.textContent = lines.join(&#39;\n&#39;);&#xA;        countEl.textContent = &#39;alive: &#39; + alive;&#xA;        genEl.textContent = &#39;gen: &#39; + generation;&#xA;    }&#xA;&#xA;    function tick() {&#xA;        step();&#xA;        render();&#xA;    }&#xA;&#xA;    function start() {&#xA;        if (!timer) timer = setInterval(tick, 150);&#xA;    }&#xA;&#xA;    function stop() {&#xA;        clearInterval(timer);&#xA;        timer = null;&#xA;    }&#xA;&#xA;    toggleBtn.addEventListener(&#39;click&#39;, function() {&#xA;        if (running) {&#xA;            stop();&#xA;            toggleBtn.textContent = &#39;Play&#39;;&#xA;        } else {&#xA;            start();&#xA;            toggleBtn.textContent = &#39;Pause&#39;;&#xA;        }&#xA;        running = !running;&#xA;    });&#xA;&#xA;    resetBtn.addEventListener(&#39;click&#39;, function() {&#xA;        init();&#xA;        generation = 0;&#xA;        render();&#xA;    });&#xA;&#xA;    el.addEventListener(&#39;click&#39;, function(e) {&#xA;        var rect = el.getBoundingClientRect();&#xA;        var style = window.getComputedStyle(el);&#xA;        var charW = el.scrollWidth / (W + 1);&#xA;        var charH = el.scrollHeight / H;&#xA;        var mx = e.clientX - rect.left;&#xA;        var my = e.clientY - rect.top;&#xA;        var cx = Math.floor(mx / charW);&#xA;        var cy = Math.floor(my / charH);&#xA;        if (cx &gt;= 0 &amp;&amp; cx &lt; W &amp;&amp; cy &gt;= 0 &amp;&amp; cy &lt; H) {&#xA;            grid[cy][cx] = grid[cy][cx] ? 0 : 1;&#xA;            render();&#xA;        }&#xA;    });&#xA;&#xA;    init();&#xA;    render();&#xA;    start();&#xA;})();&#xA;&lt;/script&gt;</description>
    </item>
    <item>
      <title>Hello World</title>
      <link>https://elwhyjay.github.io/post/hello_world/</link>
      <pubDate>Tue, 24 Sep 2024 00:00:00 +0900</pubDate>
      <guid>https://elwhyjay.github.io/post/hello_world/</guid>
      <description>&lt;pre id=&#34;donut&#34; style=&#34;font-size: 10px; line-height: 1; letter-spacing: 2px; text-align: center;&#34;&gt;&lt;/pre&gt;&#xA;&lt;script&gt;&#xA;(function() {&#xA;    var A = 1, B = 1;&#xA;    var el = document.getElementById(&#39;donut&#39;);&#xA;&#xA;    function render() {&#xA;        var b = [];&#xA;        var z = [];&#xA;        var width = 80, height = 22;&#xA;        for (var k = 0; k &lt; width * height; k++) {&#xA;            b[k] = k % width === width - 1 ? &#39;\n&#39; : &#39; &#39;;&#xA;            z[k] = 0;&#xA;        }&#xA;&#xA;        for (var j = 0; j &lt; 6.28; j += 0.07) {&#xA;            for (var i = 0; i &lt; 6.28; i += 0.02) {&#xA;                var c = Math.sin(i),&#xA;                    d = Math.cos(j),&#xA;                    e = Math.sin(A),&#xA;                    f = Math.sin(j),&#xA;                    g = Math.cos(A),&#xA;                    h = d + 2,&#xA;                    D = 1 / (c * h * e + f * g + 5),&#xA;                    l = Math.cos(i),&#xA;                    m = Math.cos(B),&#xA;                    n = Math.sin(B),&#xA;                    t = c * h * g - f * e;&#xA;&#xA;                var x = (40 + 30 * D * (l * h * m - t * n)) | 0;&#xA;                var y = (12 + 15 * D * (l * h * n + t * m)) | 0;&#xA;                var o = x + width * y;&#xA;                var N = (8 * ((f * e - c * d * g) * m - c * d * e - f * g - l * d * n)) | 0;&#xA;&#xA;                if (y &gt; 0 &amp;&amp; y &lt; height &amp;&amp; x &gt; 0 &amp;&amp; x &lt; width &amp;&amp; D &gt; z[o]) {&#xA;                    z[o] = D;&#xA;                    b[o] = &#39;.,-~:;=!*#$@&#39;[N &gt; 0 ? N : 0];&#xA;                }&#xA;            }&#xA;        }&#xA;&#xA;        el.textContent = b.join(&#39;&#39;);&#xA;        A += 0.04;&#xA;        B += 0.02;&#xA;    }&#xA;&#xA;    setInterval(render, 50);&#xA;})();&#xA;&lt;/script&gt;</description>
    </item>
  </channel>
</rss>
