<!DOCTYPE html>

<script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><style>
    .theme-toggle {
      position: fixed;
      top: 20px;
      right: 20px;
      padding: 8px;
      font-size: 1.2rem;
      cursor: pointer;
      background: none;
      border: 1px solid ;
      border-color: black;
      border-radius: 60%;
      z-index: 1000;
    }
    body[a="dark"] .theme-toggle {
        border-color: white;
    }
</style>

<html lang="ko-kr"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="google-site-verification" content="CGHN0W7w6iWZ8ggs2E8eQ_Wiq1IuSxJHXr-KLZIetgk" />
   <meta name="description" content="CUDA 기본연산
기본적인 함수설명

cudamalloc은 device memory를 할당하는 함수이다.
cudaMemcpy은 host와 device간의 데이터를 복사하는 함수이다.
cudaFree는 device memory를 해제하는 함수이다.
cudaDeviceSynchronize는 device에서 실행중인 모든 kernel이 종료될때까지 기다리는 함수이다.

덧셈연산
#include &lt;cuda_runtime.h&gt;

__global__ void vector_add(const float* A, const float* B, float* C, int N) {
    int idx = threadIdx.x &#43; blockIdx.x * blockDim.x;
    int stride = blockDim.x * gridDim.x;
    for(int i =idx;i&lt;N;i&#43;=stride) {
        C[i] = A[i] &#43; B[i];
    }
}

void solve(const float* A, const float* B, float* C, int N) {
    float *d_A, *d_B, *d_C;

    // Allocate device memory
    cudaMalloc(&amp;d_A, N * sizeof(float));
    cudaMalloc(&amp;d_B, N * sizeof(float));
    cudaMalloc(&amp;d_C, N * sizeof(float));

    // Copy input data from host to device
    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);

    // Calculate grid and block dimensions
    int threadsPerBlock = 256;
    int blocksPerGrid = (N &#43; threadsPerBlock - 1) / threadsPerBlock;

    // Launch the kernel
    vector_add&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_A, d_B, d_C, N);
    cudaDeviceSynchronize();

    // Copy result back to host
    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);
}
곱셈연산
#include &lt;cuda_runtime.h&gt;

__global__ void matrix_multiplication_kernel(const float* A, const float* B, float* C, int M, int N, int K) {
    int col = blockIdx.x * blockDim.x &#43; threadIdx.x;
    int row = blockIdx.y * blockDim.y &#43; threadIdx.y;
    if(row &lt; M &amp;&amp; col &lt; K) {
        float val = 0.0;
        for(int i =0;i&lt;N;i&#43;&#43;) {
            val &#43;= A[(row*N) &#43; i]*B[(K*i)&#43;col];
        }
        C[(row*K)&#43;col] = val;
    }

}

// A, B, C are device pointers (i.e. pointers to memory on the GPU)
// A,B,C 가 device pointer이므로 cudaMalloc과 cudaMemcpy는 생략한다.
void solve(const float* A, const float* B, float* C, int M, int N, int K) {
    dim3 threadsPerBlock(16, 16);
    dim3 blocksPerGrid((K &#43; threadsPerBlock.x - 1) / threadsPerBlock.x,
                       (M &#43; threadsPerBlock.y - 1) / threadsPerBlock.y);
    
    matrix_multiplication_kernel&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(A, B, C, M, N, K);
    cudaDeviceSynchronize();
}
A matrix의 크기가 MxN이고 B matrix의 크기가 NxK일때, C matrix의 크기는 MxK인 곱셈을 수행한다.
이 구현은 꽤 Naive한 구현이다. 이 구현에서 CUDA Kernel은 DRAM을 사용하여 각 thread가 A와 B의 행렬을 곱하는 방식으로 동작한다. 조금더 개선된 속도를 위해
shared memory를 사용하여 A와 B의 행렬을 곱하는 방식이 있다. 구현은 다음과 같다.">  
  
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-YXXYQPDYLX"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-YXXYQPDYLX');
        }
      </script>

  <title>
    
      cuda basic operation
    
  </title>


  <link rel="shortcut icon" type="image/x-icon" href="/img/favicon.ico" />
  
  
  
  <link rel="stylesheet" href="/css/main.b27fc5610be205f24ca50ff0ec7c3029a919c277b959db7ed8b6e173d918decfc1435681e9a787476bce9650012878ff0a4ac9f8ac6f8e2ee2716f8eff5cead8.css" integrity="sha512-sn/FYQviBfJMpQ/w7HwwKakZwne5Wdt&#43;2Lbhc9kY3s/BQ1aB6aeHR2vOllABKHj/CkrJ&#43;Kxvji7icW&#43;O/1zq2A==" />
  
</head>
<style>
        table {
            border-collapse: collapse;
            border: 1px solid #ebebeb;
        }
        
        th, td {
            border: 1px solid #ffffff;
            padding: 8px;
        }
        th {
            background-color: #2290e5;
        }
        
    </style>
    
    <body a="auto">
        <button class="theme-toggle" onclick="toggleTheme()">
            <span class="light-icon">🌞</span>
            <span class="dark-icon" style="display:none">🌙</span>
        </button>
        <main class="page-content" aria-label="Content">
            <div class="w">
<a href="/">..</a>


<article>
    <p class="post-meta">
        <time datetime="2025-03-05 15:22:43 &#43;0900 KST">
            2025-03-05
        </time>
    </p>

    <h1>cuda basic operation</h1>

    

    <h1 id="cuda-기본연산">CUDA 기본연산</h1>
<h2 id="기본적인-함수설명">기본적인 함수설명</h2>
<ul>
<li><code>cudamalloc</code>은 device memory를 할당하는 함수이다.</li>
<li><code>cudaMemcpy</code>은 host와 device간의 데이터를 복사하는 함수이다.</li>
<li><code>cudaFree</code>는 device memory를 해제하는 함수이다.</li>
<li><code>cudaDeviceSynchronize</code>는 device에서 실행중인 모든 kernel이 종료될때까지 기다리는 함수이다.</li>
</ul>
<h2 id="덧셈연산">덧셈연산</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C" data-lang="C"><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;cuda_runtime.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">vector_add</span>(<span style="color:#66d9ef">const</span> <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> A, <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> B, <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> C, <span style="color:#66d9ef">int</span> N) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> idx <span style="color:#f92672">=</span> threadIdx.x <span style="color:#f92672">+</span> blockIdx.x <span style="color:#f92672">*</span> blockDim.x;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> stride <span style="color:#f92672">=</span> blockDim.x <span style="color:#f92672">*</span> gridDim.x;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span>idx;i<span style="color:#f92672">&lt;</span>N;i<span style="color:#f92672">+=</span>stride) {
</span></span><span style="display:flex;"><span>        C[i] <span style="color:#f92672">=</span> A[i] <span style="color:#f92672">+</span> B[i];
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">solve</span>(<span style="color:#66d9ef">const</span> <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> A, <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> B, <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> C, <span style="color:#66d9ef">int</span> N) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> <span style="color:#f92672">*</span>d_A, <span style="color:#f92672">*</span>d_B, <span style="color:#f92672">*</span>d_C;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Allocate device memory
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#a6e22e">cudaMalloc</span>(<span style="color:#f92672">&amp;</span>d_A, N <span style="color:#f92672">*</span> <span style="color:#66d9ef">sizeof</span>(<span style="color:#66d9ef">float</span>));
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">cudaMalloc</span>(<span style="color:#f92672">&amp;</span>d_B, N <span style="color:#f92672">*</span> <span style="color:#66d9ef">sizeof</span>(<span style="color:#66d9ef">float</span>));
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">cudaMalloc</span>(<span style="color:#f92672">&amp;</span>d_C, N <span style="color:#f92672">*</span> <span style="color:#66d9ef">sizeof</span>(<span style="color:#66d9ef">float</span>));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Copy input data from host to device
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#a6e22e">cudaMemcpy</span>(d_A, A, N <span style="color:#f92672">*</span> <span style="color:#66d9ef">sizeof</span>(<span style="color:#66d9ef">float</span>), cudaMemcpyHostToDevice);
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">cudaMemcpy</span>(d_B, B, N <span style="color:#f92672">*</span> <span style="color:#66d9ef">sizeof</span>(<span style="color:#66d9ef">float</span>), cudaMemcpyHostToDevice);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Calculate grid and block dimensions
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">int</span> threadsPerBlock <span style="color:#f92672">=</span> <span style="color:#ae81ff">256</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> blocksPerGrid <span style="color:#f92672">=</span> (N <span style="color:#f92672">+</span> threadsPerBlock <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>) <span style="color:#f92672">/</span> threadsPerBlock;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Launch the kernel
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    vector_add<span style="color:#f92672">&lt;&lt;&lt;</span>blocksPerGrid, threadsPerBlock<span style="color:#f92672">&gt;&gt;&gt;</span>(d_A, d_B, d_C, N);
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">cudaDeviceSynchronize</span>();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Copy result back to host
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#a6e22e">cudaMemcpy</span>(C, d_C, N <span style="color:#f92672">*</span> <span style="color:#66d9ef">sizeof</span>(<span style="color:#66d9ef">float</span>), cudaMemcpyDeviceToHost);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Free device memory
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#a6e22e">cudaFree</span>(d_A);
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">cudaFree</span>(d_B);
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">cudaFree</span>(d_C);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="곱셈연산">곱셈연산</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C" data-lang="C"><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;cuda_runtime.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>__global__ <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">matrix_multiplication_kernel</span>(<span style="color:#66d9ef">const</span> <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> A, <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> B, <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> C, <span style="color:#66d9ef">int</span> M, <span style="color:#66d9ef">int</span> N, <span style="color:#66d9ef">int</span> K) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> col <span style="color:#f92672">=</span> blockIdx.x <span style="color:#f92672">*</span> blockDim.x <span style="color:#f92672">+</span> threadIdx.x;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> row <span style="color:#f92672">=</span> blockIdx.y <span style="color:#f92672">*</span> blockDim.y <span style="color:#f92672">+</span> threadIdx.y;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span>(row <span style="color:#f92672">&lt;</span> M <span style="color:#f92672">&amp;&amp;</span> col <span style="color:#f92672">&lt;</span> K) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">float</span> val <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>;
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>;i<span style="color:#f92672">&lt;</span>N;i<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>            val <span style="color:#f92672">+=</span> A[(row<span style="color:#f92672">*</span>N) <span style="color:#f92672">+</span> i]<span style="color:#f92672">*</span>B[(K<span style="color:#f92672">*</span>i)<span style="color:#f92672">+</span>col];
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        C[(row<span style="color:#f92672">*</span>K)<span style="color:#f92672">+</span>col] <span style="color:#f92672">=</span> val;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// A, B, C are device pointers (i.e. pointers to memory on the GPU)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// A,B,C 가 device pointer이므로 cudaMalloc과 cudaMemcpy는 생략한다.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">solve</span>(<span style="color:#66d9ef">const</span> <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> A, <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> B, <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> C, <span style="color:#66d9ef">int</span> M, <span style="color:#66d9ef">int</span> N, <span style="color:#66d9ef">int</span> K) {
</span></span><span style="display:flex;"><span>    dim3 <span style="color:#a6e22e">threadsPerBlock</span>(<span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">16</span>);
</span></span><span style="display:flex;"><span>    dim3 <span style="color:#a6e22e">blocksPerGrid</span>((K <span style="color:#f92672">+</span> threadsPerBlock.x <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>) <span style="color:#f92672">/</span> threadsPerBlock.x,
</span></span><span style="display:flex;"><span>                       (M <span style="color:#f92672">+</span> threadsPerBlock.y <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>) <span style="color:#f92672">/</span> threadsPerBlock.y);
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    matrix_multiplication_kernel<span style="color:#f92672">&lt;&lt;&lt;</span>blocksPerGrid, threadsPerBlock<span style="color:#f92672">&gt;&gt;&gt;</span>(A, B, C, M, N, K);
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">cudaDeviceSynchronize</span>();
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>A matrix의 크기가 MxN이고 B matrix의 크기가 NxK일때, C matrix의 크기는 MxK인 곱셈을 수행한다.
이 구현은 꽤 Naive한 구현이다. 이 구현에서 CUDA Kernel은 DRAM을 사용하여 각 thread가 A와 B의 행렬을 곱하는 방식으로 동작한다. 조금더 개선된 속도를 위해
shared memory를 사용하여 A와 B의 행렬을 곱하는 방식이 있다. 구현은 다음과 같다.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-C" data-lang="C"><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;cuda_runtime.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#define TILE_SIZE 16
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>__global__ <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">matrix_multiplication_kernel_with_shared_memory</span>(<span style="color:#66d9ef">const</span> <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> A, <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> B, <span style="color:#66d9ef">float</span><span style="color:#f92672">*</span> C, <span style="color:#66d9ef">int</span> M, <span style="color:#66d9ef">int</span> N, <span style="color:#66d9ef">int</span> K) {
</span></span><span style="display:flex;"><span>    __shared__ <span style="color:#66d9ef">float</span> A_shared[TILE_SIZE][TILE_SIZE];
</span></span><span style="display:flex;"><span>    __shared__ <span style="color:#66d9ef">float</span> B_shared[TILE_SIZE][TILE_SIZE];
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> col <span style="color:#f92672">=</span> blockIdx.x <span style="color:#f92672">*</span> TILE_SIZE <span style="color:#f92672">+</span> threadIdx.x;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> row <span style="color:#f92672">=</span> blockIdx.y <span style="color:#f92672">*</span> TILE_SIZE <span style="color:#f92672">+</span> threadIdx.y;   
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> val <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;</span> (N <span style="color:#f92672">+</span> TILE_SIZE <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>) <span style="color:#f92672">/</span> TILE_SIZE; i<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span>(row <span style="color:#f92672">&lt;</span> M <span style="color:#f92672">&amp;&amp;</span> i <span style="color:#f92672">*</span> TILE_SIZE <span style="color:#f92672">+</span> threadIdx.x <span style="color:#f92672">&lt;</span> N) {
</span></span><span style="display:flex;"><span>            A_shared[threadIdx.y][threadIdx.x] <span style="color:#f92672">=</span> A[row <span style="color:#f92672">*</span> N <span style="color:#f92672">+</span> i <span style="color:#f92672">*</span> TILE_SIZE <span style="color:#f92672">+</span> threadIdx.x];
</span></span><span style="display:flex;"><span>        } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>            A_shared[threadIdx.y][threadIdx.x] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span>(col <span style="color:#f92672">&lt;</span> K <span style="color:#f92672">&amp;&amp;</span> i <span style="color:#f92672">*</span> TILE_SIZE <span style="color:#f92672">+</span> threadIdx.y <span style="color:#f92672">&lt;</span> N) {
</span></span><span style="display:flex;"><span>            B_shared[threadIdx.y][threadIdx.x] <span style="color:#f92672">=</span> B[(i <span style="color:#f92672">*</span> TILE_SIZE <span style="color:#f92672">+</span> threadIdx.y) <span style="color:#f92672">*</span> K <span style="color:#f92672">+</span> col];
</span></span><span style="display:flex;"><span>        } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>            B_shared[threadIdx.y][threadIdx.x] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">__syncthreads</span>();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> j <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; j <span style="color:#f92672">&lt;</span> TILE_SIZE; j<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>            val <span style="color:#f92672">+=</span> A_shared[threadIdx.y][j] <span style="color:#f92672">*</span> B_shared[j][threadIdx.x];
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">__syncthreads</span>();
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span>(row <span style="color:#f92672">&lt;</span> M <span style="color:#f92672">&amp;&amp;</span> col <span style="color:#f92672">&lt;</span> K) {
</span></span><span style="display:flex;"><span>        C[row <span style="color:#f92672">*</span> K <span style="color:#f92672">+</span> col] <span style="color:#f92672">=</span> val;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>두 가지 동작원리를 그림으로 살펴보자</p>
<div style="display: flex; gap: 20px; margin-bottom: 20px;">
    
      
        
        <figure style="width: 50%; margin: 0;">
          <img src="/img/cuda_matmul_naive.png" style="width: 100%; height: 380px; object-fit: contain;">
          <figcaption style="text-align: center; font-size: 0.9em; margin-top: 8px;">naive matmul</figcaption>
        </figure>
      
    
      
    
      
        
        <figure style="width: 50%; margin: 0;">
          <img src="/img/cuda_matmul_sharedmem.png" style="width: 100%; height: 380px; object-fit: contain;">
          <figcaption style="text-align: center; font-size: 0.9em; margin-top: 8px;">shared memory matmul</figcaption>
        </figure>
      
    
      
    
  </div>

</article>


    <script src="https://utteranc.es/client.js"
        repo="elwhyjay/blog-comment"
        issue-term="title"
        label="✨💬✨"
        theme="github-dark"
        crossorigin="anonymous"
        async>
</script>


            </div>
        </main>
        <script>
            function toggleTheme() {
              const body = document.querySelector('body');
              const currentTheme = body.getAttribute('a');
              const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
              
              body.setAttribute('a', newTheme);
              localStorage.setItem('theme', newTheme);
              
              
              const lightIcon = document.querySelector('.light-icon');
              const darkIcon = document.querySelector('.dark-icon');
              lightIcon.style.display = newTheme === 'dark' ? 'none' : 'inline';
              darkIcon.style.display = newTheme === 'dark' ? 'inline' : 'none';
            }
            
            
            document.addEventListener('DOMContentLoaded', () => {
              const savedTheme = localStorage.getItem('theme');
              if (savedTheme) {
                document.querySelector('body').setAttribute('a', savedTheme);
                
                const lightIcon = document.querySelector('.light-icon');
                const darkIcon = document.querySelector('.dark-icon');
                lightIcon.style.display = savedTheme === 'dark' ? 'none' : 'inline';
                darkIcon.style.display = savedTheme === 'dark' ? 'inline' : 'none';
              }
            });
        </script>
    </body>
</html>
