<!DOCTYPE html>

<style>
    .theme-toggle {
      position: fixed;
      top: 20px;
      right: 20px;
      padding: 8px;
      font-size: 1.2rem;
      cursor: pointer;
      background: none;
      border: 0px solid ;
      border-color: none;
      border-radius: 60%;
      z-index: 1000;
      color: inherit;
    }
</style>

<html lang="ko-kr"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="google-site-verification" content="CGHN0W7w6iWZ8ggs2E8eQ_Wiq1IuSxJHXr-KLZIetgk" />
   <meta name="description" content="Introduction
Quantization은 현재 LLM 분야에서 중요한 기술로 자리잡았다. 특히 추론을 최적화하는데 있어서 가중치를 int4, int8 등의 저정밀도 정수형으로 양자화하는 기법이 널리 사용되고 있다. 이 기법을 통해 모델의 메모리 사용량을 줄이고, 메모리 대역폭 요구사항을 낮추며, 하드웨어 가속기의 연산 처리량을 극대화할 수 있다. 하지만 양자화 기술은 만능이 아니고 많은 경우에 최적화가 요구될 수 있다.
이 글에서는 QServe에서 소개된 Kim et al. 의 논문에서 제시된 int4 양자화된 KV cache를 FP16 활성화 값으로 역양자화하는 비트 최적화 기법에 대해 살펴본다. 역양자화는 때로 과도한 연산량을 요구할 수 있기 때문에, 이를 효율적으로 처리하는 것이 중요하다. 이 최적화 기법은 computing resource를 절약하는 효과적인 방법중 하나로 이해하고 비슷한시나리오에서 사용가능할것 같다.">  
  
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-YXXYQPDYLX"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-YXXYQPDYLX');
        }
      </script>

  <title>
    
      Int4 to FP16 dequantization optimization
    
  </title>


  <link rel="shortcut icon" type="image/x-icon" href="/img/favicon.ico" />
  
  
  
  <link rel="stylesheet" href="/css/main.f851b574c8f7f906d9d8e9911c9f189f9b2b655d6dbfe90426404861dda3c29ad933703258e46b8085fa1e0ae0c2adec82bb65ffa00743e4b4bccae949802b2d.css" integrity="sha512-&#43;FG1dMj3&#43;QbZ2OmRHJ8Yn5srZV1tv&#43;kEJkBIYd2jwprZM3AyWORrgIX6Hgrgwq3sgrtl/6AHQ&#43;S0vMrpSYArLQ==" />
   <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
 
</head>
<body a="auto">
        <button class="theme-toggle" onclick="toggleTheme()">
            <span class="light-icon">
                <svg id="light-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                stroke-linejoin="round">
                <circle cx="12" cy="12" r="5"></circle>
                <line x1="12" y1="1" x2="12" y2="3"></line>
                <line x1="12" y1="21" x2="12" y2="23"></line>
                <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                <line x1="1" y1="12" x2="3" y2="12"></line>
                <line x1="21" y1="12" x2="23" y2="12"></line>
                <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
            </svg>
            </span>
            <span class="dark-icon" style="display:none">
                <svg id="dark-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                stroke-linejoin="round">
                <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                </svg>
            </span>
            
            
        </button>
        <main class="page-content" aria-label="Content">
            <div class="w">
<a href="/">..</a>


<article>
    <p class="post-meta">
        <time datetime="2025-12-02 17:44:26 &#43;0900 KST">
            2025-12-02
        </time>
    </p>

    <h1>Int4 to FP16 dequantization optimization</h1>

    

    <h2 id="introduction">Introduction</h2>
<p>Quantization은 현재 LLM 분야에서 중요한 기술로 자리잡았다. 특히 추론을 최적화하는데 있어서 가중치를 int4, int8 등의 저정밀도 정수형으로 양자화하는 기법이 널리 사용되고 있다. 이 기법을 통해 모델의 메모리 사용량을 줄이고, 메모리 대역폭 요구사항을 낮추며, 하드웨어 가속기의 연산 처리량을 극대화할 수 있다. 하지만 양자화 기술은 만능이 아니고 많은 경우에 최적화가 요구될 수 있다.</p>
<p>이 글에서는 QServe에서 소개된 <a href="https://arxiv.org/abs/2211.10017">Kim et al.</a> 의 논문에서 제시된 int4 양자화된 KV cache를 FP16 활성화 값으로 역양자화하는 비트 최적화 기법에 대해 살펴본다. 역양자화는 때로 과도한 연산량을 요구할 수 있기 때문에, 이를 효율적으로 처리하는 것이 중요하다. 이 최적화 기법은 computing resource를 절약하는 효과적인 방법중 하나로 이해하고 비슷한시나리오에서 사용가능할것 같다.</p>
<hr>
<h2 id="fp16-반정밀도-부동소수점-기본-구조">FP16 (반정밀도 부동소수점) 기본 구조</h2>
<p>FP16은 실수(부동소수점 수)를 표현하는 16비트 포맷이다. 이는 표준 단정밀도(FP32, 32비트) 대비 메모리 효율성 및 연산 처리량 증대에 유리하다.</p>
<p>FP16은 IEEE 754 표준에 따라 다음과 같이 16비트를 세 부분으로 나누어 구성된다:</p>
<ul>
<li><strong>부호 (Sign)</strong>: 1 비트</li>
<li><strong>지수 (Exponent)</strong>: 5 비트 (바이어스 $Bias=15$)</li>
<li><strong>가수/유효숫자 (Mantissa/Significand)</strong>: 10 비트</li>
</ul>
<p>FP16으로 표현되는 값 $V$의 일반적인 공식은 다음과 같다:</p>
<p>$$V = (-1)^{Sign} \times 2^{Exponent - Bias} \times (1 + Fraction)$$</p>
<h3 id="암묵적-선행-비트의-역할">암묵적 선행 비트의 역할</h3>
<p>유효숫자는 일반적으로 **정규화된 수(Normalized Number)**에서 암묵적인 선행 **$1$**을 가정하여 11비트의 정밀도를 확보한다.</p>
<ul>
<li><strong>정규화된 수</strong>: 지수 필드가 $0$이나 최대값($31$)이 아닐 때, 선행 비트는 **$1$**로 가정된다.</li>
<li><strong>비정규화된 수 (Denormalized Number)</strong>: 지수 필드가 **모두 $0$**일 때, 선행 비트는 **$0$**으로 가정된다. 이는 $0$ 주변의 매우 작은 수를 표현하여 점진적인 언더플로우를 가능하게 한다.</li>
</ul>
<hr>
<h2 id="정수-변환과-210-분기점">정수 변환과 $2^{10}$ 분기점</h2>
<p>정수 $N$을 FP16으로 변환할 때, $2^{10}=1024$는 정확도와 표현 간격이 바뀌는 중요한 분기점이다.</p>
<ol>
<li>
<p><strong>$N &lt; 1024$인 경우</strong>: 정규화 시 지수 $E \le 9$를 갖는다. 가수에 필요한 비트 수가 10비트 이하여서, $1024$ 미만의 모든 정수는 FP16으로 <strong>오차 없이 정확하게 표현된다.</strong></p>
</li>
<li>
<p><strong>$N \ge 1024$인 경우</strong>: 정규화 시 지수 $E \ge 10$을 갖는다.</p>
<ul>
<li>$N=1027$을 예로 들면, 정규화 형태는 $1.0000000011_2 \times 2^{10}$이다.</li>
<li>$V = (1 + Fraction) \times 2^{10}$의 형태에서, 가수의 최소 단위 $ULP = 2^{-10}$이 $2^{10}$과 곱해지면서 표현 간격 $\Delta V$는 $1$이 된다.
$$\Delta V = 2^{-10} \times 2^{10} = 1$$</li>
<li>따라서 $1024$ 이상의 정수는 <strong>$1$ 간격으로 떨어져 있는 정수</strong>만 오차 없이 표현할 수 있다.</li>
</ul>
</li>
</ol>
<h2 id="int4-to-fp16-역양자화-최적화-기법">Int4 $\to$ FP16 역양자화 최적화 기법</h2>
<p>대규모 MoE(Mixture of Experts) 모델의 추론 최적화 과정에서, 4/8비트 정수형 가중치($Int8/Int4$)를 FP16 활성화 값으로 역양자화(Dequantize)하는 과정의 성능 향상을 위해 FP16의 비트 패턴 특징이 활용된다. 이 방법은 느린 네이티브 $Int \to Float$ 변환(I2F)을 대체한다.</p>
<h3 id="핵심-관찰-사항">핵심 관찰 사항</h3>
<ol>
<li>
<p><strong>관찰 1</strong>: FP16에서 $1024 &lt; X &lt; 2048$ 범위의 정수 $X$는 $1024$가 지수 비트에 표현되고, $int(X-1024)$는 <strong>가수 비트에 직접 저장된다</strong>.</p>
</li>
<li>
<p><strong>관찰 2</strong>: $0 \le Y &lt; 1024$인 정수 $Y$에 대해, $Y+1024$의 FP16 표현은 $1024$의 16진수 표현($0x6400$)에 $Y$를 <strong>OR 연산</strong>하여 쉽게 만들 수 있다.</p>
</li>
</ol>
<h3 id="int4-역양자화-과정-최적화">Int4 역양자화 과정 최적화</h3>
<ol>
<li>
<p><strong>오프셋 추가</strong>: 부호 있는 $Int4$ 가중치에 $\mathbf{128}$을 더하여 $unsigned$ $Int4$ 값($W_{+}$)을 만든다.</p>
</li>
<li>
<p><strong>고속 FP16 생성</strong>: $W_{+}$의 값($e_i$)에 <strong>$1024$를 더한 형태</strong>($e_i + 1024$)의 FP16 비트 패턴을 <strong>관찰 2</strong>를 통해 <strong>비트 연산</strong>으로 생성한다.</p>
</li>
<li>
<p><strong>오프셋 제거</strong>: 생성된 FP16 값은 $1024$ (비트 트릭 오프셋)와 $128$ (부호 변환 오프셋)을 포함하고 있다. 따라서 **총 오프셋 $\mathbf{1152}$**를 $FP16$ 부동소수점 뺄셈 연산으로 제거하여 원래의 부호 있는 $Int8$ 값을 $FP16$으로 복구한다.</p>
</li>
</ol>
<p>이러한 최적화는 $Int \to Float$ 변환을 고속 ALU 및 $FP16$ 명령어로 대체하며, 역양자화 단계를 GEMM 커널에 융합하여 메모리 트래픽 병목 현상을 해소한다.</p>
<h2 id="int4-역양자화-커널-구현-예제">Int4 역양자화 커널 구현 예제</h2>
<p>다음은 Int4 양자화 가중치를 FP16으로 역양자화하는 CUDA 커널 구현이다.
출처는 다음 <a href="https://github.com/mit-han-lab/omniserve">github</a>를 참조하라.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#66d9ef">inline</span> __device__ uint4 <span style="color:#a6e22e">dequantize_s4_to_fp16x2</span>(<span style="color:#66d9ef">uint32_t</span> <span style="color:#66d9ef">const</span><span style="color:#f92672">&amp;</span> source) {
</span></span><span style="display:flex;"><span>    uint4 result;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">uint32_t</span><span style="color:#f92672">*</span>      h   <span style="color:#f92672">=</span> reinterpret_cast<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">uint32_t</span><span style="color:#f92672">*&gt;</span>(<span style="color:#f92672">&amp;</span>result);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">uint32_t</span> <span style="color:#66d9ef">const</span> i4s <span style="color:#f92672">=</span> reinterpret_cast<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">uint32_t</span> <span style="color:#66d9ef">const</span><span style="color:#f92672">&amp;&gt;</span>(source);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// First, we extract the i4s and construct an intermediate fp16 number.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">static</span> constexpr <span style="color:#66d9ef">uint32_t</span> immLut                <span style="color:#f92672">=</span> (<span style="color:#ae81ff">0xf0</span> <span style="color:#f92672">&amp;</span> <span style="color:#ae81ff">0xcc</span>) <span style="color:#f92672">|</span> <span style="color:#ae81ff">0xaa</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">static</span> constexpr <span style="color:#66d9ef">uint32_t</span> BOTTOM_MASK           <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x000f000f</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">static</span> constexpr <span style="color:#66d9ef">uint32_t</span> TOP_MASK              <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x00f000f0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">static</span> constexpr <span style="color:#66d9ef">uint32_t</span> I4s_TO_F16s_MAGIC_NUM <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x64006400</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Note that the entire sequence only requires 1 shift instruction.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">uint32_t</span> top_i4s <span style="color:#f92672">=</span> i4s <span style="color:#f92672">&gt;&gt;</span> <span style="color:#ae81ff">8</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Extract elt_01 - (i4s &amp; 0x000f000f) | 0x64006400
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">asm</span> <span style="color:#66d9ef">volatile</span>(<span style="color:#e6db74">&#34;lop3.b32 %0, %1, %2, %3, %4;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;=r&#34;</span>(h[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;r&#34;</span>(i4s), <span style="color:#e6db74">&#34;n&#34;</span>(BOTTOM_MASK), <span style="color:#e6db74">&#34;n&#34;</span>(I4s_TO_F16s_MAGIC_NUM), <span style="color:#e6db74">&#34;n&#34;</span>(immLut));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Extract elt_23 (i4s &amp; 0x00f000f0) | 0x64006400
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">asm</span> <span style="color:#66d9ef">volatile</span>(<span style="color:#e6db74">&#34;lop3.b32 %0, %1, %2, %3, %4;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;=r&#34;</span>(h[<span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;r&#34;</span>(i4s), <span style="color:#e6db74">&#34;n&#34;</span>(TOP_MASK), <span style="color:#e6db74">&#34;n&#34;</span>(I4s_TO_F16s_MAGIC_NUM), <span style="color:#e6db74">&#34;n&#34;</span>(immLut));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Extract elt_45 (top_i4s &amp; 0x000f000f) | 0x64006400
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">asm</span> <span style="color:#66d9ef">volatile</span>(<span style="color:#e6db74">&#34;lop3.b32 %0, %1, %2, %3, %4;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;=r&#34;</span>(h[<span style="color:#ae81ff">2</span>])
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;r&#34;</span>(top_i4s), <span style="color:#e6db74">&#34;n&#34;</span>(BOTTOM_MASK), <span style="color:#e6db74">&#34;n&#34;</span>(I4s_TO_F16s_MAGIC_NUM), <span style="color:#e6db74">&#34;n&#34;</span>(immLut));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Extract elt_67 (top_i4s &amp; 0x00f000f0) | 0x64006400
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">asm</span> <span style="color:#66d9ef">volatile</span>(<span style="color:#e6db74">&#34;lop3.b32 %0, %1, %2, %3, %4;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;=r&#34;</span>(h[<span style="color:#ae81ff">3</span>])
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;r&#34;</span>(top_i4s), <span style="color:#e6db74">&#34;n&#34;</span>(TOP_MASK), <span style="color:#e6db74">&#34;n&#34;</span>(I4s_TO_F16s_MAGIC_NUM), <span style="color:#e6db74">&#34;n&#34;</span>(immLut));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// FP16 magic numbers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">static</span> constexpr <span style="color:#66d9ef">uint32_t</span> FP16_TOP_MAGIC_NUM <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x64006400</span>;  <span style="color:#75715e">// {1024, 1024}
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">static</span> constexpr <span style="color:#66d9ef">uint32_t</span> ONE_SIXTEENTH <span style="color:#f92672">=</span> <span style="color:#ae81ff">0x2c002c00</span>;       <span style="color:#75715e">// {1/16, 1/16}
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">static</span> constexpr <span style="color:#66d9ef">uint32_t</span> NEG_64 <span style="color:#f92672">=</span> <span style="color:#ae81ff">0xd400d400</span>;              <span style="color:#75715e">// {-64, -64}
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Finally, we construct the output numbers.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">asm</span> <span style="color:#66d9ef">volatile</span>(<span style="color:#e6db74">&#34;sub.f16x2 %0, %1, %2;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;=r&#34;</span>(h[<span style="color:#ae81ff">0</span>]) <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;r&#34;</span>(h[<span style="color:#ae81ff">0</span>]), <span style="color:#e6db74">&#34;r&#34;</span>(FP16_TOP_MAGIC_NUM));
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">asm</span> <span style="color:#66d9ef">volatile</span>(<span style="color:#e6db74">&#34;fma.rn.f16x2 %0, %1, %2, %3;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;=r&#34;</span>(h[<span style="color:#ae81ff">1</span>]) <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;r&#34;</span>(h[<span style="color:#ae81ff">1</span>]), <span style="color:#e6db74">&#34;r&#34;</span>(ONE_SIXTEENTH), <span style="color:#e6db74">&#34;r&#34;</span>(NEG_64));
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">asm</span> <span style="color:#66d9ef">volatile</span>(<span style="color:#e6db74">&#34;sub.f16x2 %0, %1, %2;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;=r&#34;</span>(h[<span style="color:#ae81ff">2</span>]) <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;r&#34;</span>(h[<span style="color:#ae81ff">2</span>]), <span style="color:#e6db74">&#34;r&#34;</span>(FP16_TOP_MAGIC_NUM));
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">asm</span> <span style="color:#66d9ef">volatile</span>(<span style="color:#e6db74">&#34;fma.rn.f16x2 %0, %1, %2, %3;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;=r&#34;</span>(h[<span style="color:#ae81ff">3</span>]) <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;r&#34;</span>(h[<span style="color:#ae81ff">3</span>]), <span style="color:#e6db74">&#34;r&#34;</span>(ONE_SIXTEENTH), <span style="color:#e6db74">&#34;r&#34;</span>(NEG_64));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> result;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="구현-분석">구현 분석</h3>
<p>이 커널은 다음과 같은 특징을 갖는다:</p>
<ul>
<li>$Int4$로 양자화된 8개의 가중치 요소($e_0$ ~ $e_7$)를 담고 있는 단일 $uint32_t$ 변수(<code>source</code>)를 입력받아, $half2$ (32비트 레지스터에 FP16 2개) 형식의 4개 레지스터(<code>uint4 result</code>)에 담긴 $FP16$ 결과로 역양자화한다.</li>
<li><strong>최적화 목표</strong>: $Int \to Float$ 변환 명령어 대신 **비트 연산 (LOP3)**과 **고속 $FP16$ 연산 (SUB.F16X2, FMA.RN.F16X2)**을 사용하여 처리량(throughput)을 높인다.</li>
<li><code>source</code> ($uint32_t$)는 8개의 $Int4$ 가중치 요소($e_0$ ~ $e_7$)를 담고 있으며, $\mathbf{8}$이 더해져 <strong>부호 없는($W_{+}$) 상태</strong>이다.</li>
</ul>
<h3 id="주요-상수-정의">주요 상수 정의</h3>
<table>
  <thead>
      <tr>
          <th style="text-align: left"><strong>상수</strong></th>
          <th style="text-align: left"><strong>값</strong></th>
          <th style="text-align: left"><strong>의미 (FP16 최적화 관점)</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">$\text{I4s_TO_F16s_MAGIC_NUM}$</td>
          <td style="text-align: left">$\mathbf{0x64006400}$</td>
          <td style="text-align: left">$half2$로 표현된 $\mathbf{{1024, 1024}}$의 비트 패턴 (관찰 2)</td>
      </tr>
      <tr>
          <td style="text-align: left">$\text{BOTTOM_MASK}$</td>
          <td style="text-align: left">$\mathbf{0x000f000f}$</td>
          <td style="text-align: left">$Int4$ 요소 중 하위 비트들을 마스킹하여 추출</td>
      </tr>
      <tr>
          <td style="text-align: left">$\text{TOP_MASK}$</td>
          <td style="text-align: left">$\mathbf{0x00f000f0}$</td>
          <td style="text-align: left">$Int4$ 요소 중 상위 비트들을 마스킹하여 추출</td>
      </tr>
  </tbody>
</table>
<h3 id="lop3-명령어-분석">$LOP3$ 명령어 분석</h3>
<p><code>asm volatile(&quot;lop3.b32&quot; %0, %1, %2, %3, %4;\n&quot;)</code>는 $PTX$의 논리 연산자 $LOP3$를 사용하여 다음 연산을 수행한다. 이는 $AND$, $OR$, $NOT$ 등을 조합하는 고성능 단일 명령어이다.</p>
<p>$$h[i] = (i4s\quad AND\quad  MASK)\quad  OR\quad  \mathbf{0x64006400}$$</p>
<ol>
<li>
<p><strong>마스킹 ($AND$)</strong>: 입력 $i4s$에서 해당하는 $Int4$ 요소들의 비트만 추출한다.</p>
</li>
<li>
<p><strong>OR 연산</strong>: 추출된 $Int4$ 값($Y$)에 $\mathbf{0x64006400}$ (1024)를 $OR$ 연산한다. 이 연산은 논문의 <strong>관찰 2</strong>를 활용하여 $\mathbf{{e_i+1024, e_{i+1}+1024}}$의 $FP16$ 비트 패턴을 <strong>고속으로</strong> 생성한다.</p>
</li>
</ol>
<p>총 4개의 $LOP3$ 명령어로 8개의 $Int4$ 요소가 $FP16$ 비트 패턴으로 저장된다. 특히 $elt_{23}$과 $elt_{67}$은 시프트 없이 처리되기 때문에, $top_i4s$에 필요한 <strong>단 하나의 시프트 명령</strong>만 사용된다.</p>
<h3 id="최종-fp16-값-복구">최종 $FP16$ 값 복구</h3>
<p>이제 비트 패턴으로 만들어진 임시 $FP16$ 값에 오프셋 제거 및 스케일링을 수행한다.</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left"><strong>상수</strong></th>
          <th style="text-align: left"><strong>값</strong></th>
          <th style="text-align: left"><strong>의미</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">$\text{FP16 _ TOP_ MAGIC_ NUM}$</td>
          <td style="text-align: left">$\mathbf{0x64006400}$</td>
          <td style="text-align: left">$half2$로 표현된 $\mathbf{{1024, 1024}}$</td>
      </tr>
      <tr>
          <td style="text-align: left">$\text{ONE_SIXTEENTH}$</td>
          <td style="text-align: left">$\mathbf{0x2c002c00}$</td>
          <td style="text-align: left">$half2$로 표현된 $\mathbf{{1/16, 1/16}}$</td>
      </tr>
      <tr>
          <td style="text-align: left">$\text{NEG_64}$</td>
          <td style="text-align: left">$\mathbf{0xd400d400}$</td>
          <td style="text-align: left">$half2$로 표현된 $\mathbf{{-64, -64}}$</td>
      </tr>
  </tbody>
</table>
<h3 id="int4의-총-오프셋-계산">$Int4$의 총 오프셋 계산</h3>
<p>논문에 따르면, $Int4$는 원래 부호 있는($[-8, 7]$) 값이었다.</p>
<ul>
<li><strong>부호 변환 오프셋</strong>: $8$을 더해 $unsigned$ $Int4$ ($[0, 15]$)로 만든다.</li>
<li><strong>비트 트릭 오프셋</strong>: $1024$를 더해 $FP16$ 비트 패턴을 만든다.</li>
</ul>
<p>따라서 총 오프셋은 $1024 + 8 = \mathbf{1032}$이다.</p>
<h3 id="연산-명령어-분석">연산 명령어 분석</h3>
<p>코드는 4개의 $half2$ 쌍을 두 종류의 연산으로 처리한다: $elt_{01}, elt_{45}$는 $SUB$, $elt_{23}, elt_{67}$은 $FMA$ (Fused Multiply-Add)이다.</p>
<p><strong>A. $elt_{01}$ 및 $elt_{45}$ 처리 (SUB):</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#75715e">// Convert elt_01
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">asm</span> <span style="color:#66d9ef">volatile</span>(<span style="color:#e6db74">&#34;sub.f16x2 %0, %1, %2;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;=r&#34;</span>(h[<span style="color:#ae81ff">0</span>]) <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;r&#34;</span>(h[<span style="color:#ae81ff">0</span>]), <span style="color:#e6db74">&#34;r&#34;</span>(FP16_TOP_MAGIC_NUM));
</span></span></code></pre></div><ul>
<li>$\text{FP16_TOP_MAGIC_NUM}$은 $\mathbf{{1024, 1024}}$이다.</li>
<li>이 연산은 $FP16$ 값에서 $1024$를 뺀다.</li>
<li>구현에서는 논문의 $Int4$ 최적화 규칙($1032$를 빼야 함)을 직접 따르지 않고, <strong>$1024$만 빼고 있다</strong>. 나머지 $\mathbf{8}$에 대한 처리는 다른 부분(스케일링)에 통합되어 있다.</li>
</ul>
<p><strong>B. $elt_{23}$ 및 $elt_{67}$ 처리 (FMA):</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#75715e">// Convert elt_23
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">asm</span> <span style="color:#66d9ef">volatile</span>(<span style="color:#e6db74">&#34;fma.rn.f16x2 %0, %1, %2, %3;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;=r&#34;</span>(h[<span style="color:#ae81ff">1</span>]) <span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;r&#34;</span>(h[<span style="color:#ae81ff">1</span>]), <span style="color:#e6db74">&#34;r&#34;</span>(ONE_SIXTEENTH), <span style="color:#e6db74">&#34;r&#34;</span>(NEG_64));
</span></span></code></pre></div><p>$FMA$ 연산은 $A \times B + C$ 형태이다.
$$result = h[1] \times \lbrace 1/16, 1/16 \rbrace + \lbrace -64, -64 \rbrace$$</p>
<ul>
<li>$h[1]$ (임시 $FP16$ 값)은 $\mathbf{{e_{2}+1024, e_{3}+1024}}$를 나타낸다.</li>
<li>$e_i$는 $Int4$ 가중치로, 최종 역양자화는 $W_{dq} = e_i \times S$ (Scale)로 표현된다.</li>
</ul>
<p>이 $FMA$ 연산은 $Int8$ 역양자화 알고리즘과는 다른 스케일링 기반의 역양자화 공식을 따르는 것이다.: $W_{dq} = IntToFloat(W_{quantized}) \times Scale$.</p>
<p>$\mathbf{ \lbrace 1/16, 1/16 \rbrace}$은 스케일 값으로 사용되고, $\mathbf{\lbrace -64, -64 \rbrace}$는 오프셋을 상쇄하는 역할을 한다. 이는 $SUB$ 연산과 달리 전체 스케일링이 $FMA$로 융합되어 처리되는 복잡한 로직을 내포하고 있다.</p>
<h2 id="결론">결론</h2>
<p>FP16 포맷의 구조적 특징, 특히 $2^{10}$을 기준으로 정수가 표현되는 방식과 비트 패턴이 값에 대응되는 방식을 활용하여, 대규모 AI 모델 추론 시 $Int4$ 양자화 가중치의 역양자화 과정을 효율적으로 수행할 수 있다.</p>
<h2 id="references">References</h2>
<ol>
<li><a href="https://arxiv.org/abs/2405.04532">QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving</a></li>
<li><a href="https://arxiv.org/abs/2211.10017">Who Says Elephants Can&rsquo;t Run: Bringing Large Scale MoE Models into Cloud Scale Production</a></li>
<li><a href="https://ieeexplore.ieee.org/document/8766229">IEEE 754 Standard for Floating-Point Arithmetic</a></li>
<li><a href="https://docs.nvidia.com/cuda/parallel-thread-execution/">NVIDIA CUDA Programming Guide - PTX ISA</a></li>
</ol>

</article>


    <script src="https://utteranc.es/client.js"
        repo="elwhyjay/blog-comment"
        issue-term="title"
        label="✨💬✨"
        theme="github-dark"
        crossorigin="anonymous"
        async>
</script>


            </div>
        </main>
        <script>
            
            function getEffectiveTheme(theme) {
              if (theme === 'auto') {
                return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
              }
              return theme;
            }

            function updateIcons(effectiveTheme) {
              const lightIcon = document.querySelector('.light-icon');
              const darkIcon = document.querySelector('.dark-icon');
              lightIcon.style.display = effectiveTheme === 'dark' ? 'none' : 'inline';
              darkIcon.style.display = effectiveTheme === 'dark' ? 'inline' : 'none';
            }

            function toggleTheme() {
              const body = document.querySelector('body');
              const currentTheme = body.getAttribute('a');
              const effective = getEffectiveTheme(currentTheme);
              const newTheme = effective === 'dark' ? 'light' : 'dark';

              body.setAttribute('a', newTheme);
              localStorage.setItem('theme', newTheme);
              updateIcons(newTheme);
            }

            
            document.addEventListener('DOMContentLoaded', () => {
              const savedTheme = localStorage.getItem('theme');
              if (savedTheme) {
                document.querySelector('body').setAttribute('a', savedTheme);
                updateIcons(savedTheme);
              } else {
                
                updateIcons(getEffectiveTheme('auto'));
              }
            });
        </script>
    </body>
</html>
