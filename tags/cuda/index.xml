<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CUDA on Yongjun&#39;s blog</title>
    <link>http://localhost:1313/tags/cuda/</link>
    <description>Recent content in CUDA on Yongjun&#39;s blog</description>
    <generator>Hugo</generator>
    <language>ko-kr</language>
    <lastBuildDate>Sun, 28 Dec 2025 21:59:14 +0900</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/cuda/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Data_format</title>
      <link>http://localhost:1313/post/data_format/</link>
      <pubDate>Sun, 28 Dec 2025 21:59:14 +0900</pubDate>
      <guid>http://localhost:1313/post/data_format/</guid>
      <description>&lt;h1 id=&#34;현대-ai-데이터-타입-ml-엔지니어와-cuda-개발자를-위한-기술-심층-분석&#34;&gt;현대 AI 데이터 타입: ML 엔지니어와 CUDA 개발자를 위한 기술 심층 분석&lt;/h1&gt;&#xA;&lt;p&gt;저정밀도 수치 포맷은 효율적인 AI 추론의 핵심이 되었으며, &lt;strong&gt;FP8&lt;/strong&gt;은 Hopper GPU에서 &lt;strong&gt;2배의 처리량 증가&lt;/strong&gt;를 제공하면서 FP16에 가까운 정확도를 유지하고, &lt;strong&gt;INT4 가중치 전용(weight-only) 양자화&lt;/strong&gt;는 70B 파라미터 모델을 단일 48GB GPU에서 실행할 수 있게 해준다. 이 보고서는 15개 이상의 데이터 포맷에 대한 수학적 명세, 4세대 NVIDIA 아키텍처 전반에 걸친 하드웨어별 성능 특성, 그리고 양자화 알고리즘에 대한 정량적 분석을 제공한다. 이는 프로덕션 LLM 시스템을 배포하는 데 필수적인 지식이다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gpu_architec</title>
      <link>http://localhost:1313/post/gpu_architec/</link>
      <pubDate>Wed, 06 Aug 2025 12:22:45 +0900</pubDate>
      <guid>http://localhost:1313/post/gpu_architec/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;gpu programming을 하기위해서는 gpu architecture에 대한 이해가 필요하다. gpu가 무엇인지는 현재에와서는 모르는 사람이 없을것이다.&#xA;때문에 gpu에 대한 소개는 생략하고 gpu architecture를 곧바로 살펴보자&lt;/p&gt;&#xA;&lt;h2 id=&#34;gpu-hardware-architecture&#34;&gt;GPU Hardware Architecture&lt;/h2&gt;&#xA;&lt;p&gt;gpu architecture는 크게 다음과 같은 요소로 구성된다.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Streaming Multiprocessors (SMs)&lt;/strong&gt;: GPU의 핵심 컴퓨팅 유닛으로, 병렬 처리를 수행한다. 각 SM은 여러 개의 CUDA 코어를 포함하고 있으며, 동시에 여러 스레드를 실행할 수 있다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;HBM (High Bandwidth Memory)&lt;/strong&gt;: GPU의 글로벌 메모리로, 데이터 전송 속도가 매우 빠르다. HBM은 GPU와 CPU 간의 데이터 전송을 최적화하여 높은 성능을 제공한다. DRAM을 적층해 만든 구조로 CPU에서 DRAM의 역할과 유사하다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;L2 Cache&lt;/strong&gt;: GPU의 L2 캐시는 데이터 접근 속도를 높이기 위해 사용된다. L2 캐시는 GPU와 HBM 사이의 중간 캐시 역할을 하며, 자주 사용되는 데이터를 저장하여 빠른 접근을 가능하게 한다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;NVLink&lt;/strong&gt;: 다른 GPU와의 연결을 위한 인터페이스로 , 다중 GPU 시스템에서 높은 대역폭을 제공한다. NVLink는 GPU 간의 데이터 전송 속도를 향상시켜, 병렬 처리 성능을 극대화한다.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;streaming-multiprocessors-sms&#34;&gt;Streaming Multiprocessors (SMs)&lt;/h3&gt;&#xA;&lt;p&gt;SMs는 GPU의 핵심 컴퓨팅 유닛으로, 병렬 처리를 수행한다. 각 SM은 다음과 같은 구성 요소로 이루어져 있다:&lt;/p&gt;</description>
    </item>
    <item>
      <title>cuda basic operation</title>
      <link>http://localhost:1313/post/cuda-basic-operation/</link>
      <pubDate>Wed, 05 Mar 2025 15:22:43 +0900</pubDate>
      <guid>http://localhost:1313/post/cuda-basic-operation/</guid>
      <description>&lt;h1 id=&#34;cuda-기본연산&#34;&gt;CUDA 기본연산&lt;/h1&gt;&#xA;&lt;h2 id=&#34;기본적인-함수설명&#34;&gt;기본적인 함수설명&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;cudamalloc&lt;/code&gt;은 device memory를 할당하는 함수이다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;cudaMemcpy&lt;/code&gt;은 host와 device간의 데이터를 복사하는 함수이다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;cudaFree&lt;/code&gt;는 device memory를 해제하는 함수이다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;cudaDeviceSynchronize&lt;/code&gt;는 device에서 실행중인 모든 kernel이 종료될때까지 기다리는 함수이다.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;덧셈연산&#34;&gt;덧셈연산&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;cuda_runtime.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;__global__ &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vector_add&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; A, &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; B, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; C, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; N) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; threadIdx.x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; blockIdx.x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blockDim.x;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; stride &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; blockDim.x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; gridDim.x;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;idx;i&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;N;i&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;stride) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        C[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; A[i] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; B[i];&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;solve&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; A, &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; B, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; C, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; N) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d_A, &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d_B, &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d_C;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Allocate device memory&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaMalloc&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;d_A, N &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;));&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaMalloc&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;d_B, N &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;));&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaMalloc&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;d_C, N &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;));&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Copy input data from host to device&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaMemcpy&lt;/span&gt;(d_A, A, N &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;), cudaMemcpyHostToDevice);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaMemcpy&lt;/span&gt;(d_B, B, N &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;), cudaMemcpyHostToDevice);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Calculate grid and block dimensions&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; threadsPerBlock &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; blocksPerGrid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (N &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threadsPerBlock &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; threadsPerBlock;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Launch the kernel&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    vector_add&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;blocksPerGrid, threadsPerBlock&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(d_A, d_B, d_C, N);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaDeviceSynchronize&lt;/span&gt;();&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Copy result back to host&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaMemcpy&lt;/span&gt;(C, d_C, N &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;), cudaMemcpyDeviceToHost);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// Free device memory&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaFree&lt;/span&gt;(d_A);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaFree&lt;/span&gt;(d_B);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaFree&lt;/span&gt;(d_C);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;곱셈연산&#34;&gt;곱셈연산&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;cuda_runtime.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;__global__ &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;matrix_multiplication_kernel&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; A, &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; B, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; C, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; M, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; N, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; K) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; col &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; blockIdx.x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blockDim.x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threadIdx.x;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; row &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; blockIdx.y &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blockDim.y &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threadIdx.y;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt;(row &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; M &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; col &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; K) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; val &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;;i&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;N;i&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            val &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; A[(row&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;N) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; i]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;B[(K&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;i)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;col];&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        C[(row&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;K)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;col] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; val;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// A, B, C are device pointers (i.e. pointers to memory on the GPU)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// A,B,C 가 device pointer이므로 cudaMalloc과 cudaMemcpy는 생략한다.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;solve&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; A, &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; B, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; C, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; M, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; N, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; K) {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    dim3 &lt;span style=&#34;color:#a6e22e&#34;&gt;threadsPerBlock&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    dim3 &lt;span style=&#34;color:#a6e22e&#34;&gt;blocksPerGrid&lt;/span&gt;((K &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threadsPerBlock.x &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; threadsPerBlock.x,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                       (M &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threadsPerBlock.y &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; threadsPerBlock.y);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    matrix_multiplication_kernel&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;blocksPerGrid, threadsPerBlock&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(A, B, C, M, N, K);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;cudaDeviceSynchronize&lt;/span&gt;();&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;A matrix의 크기가 MxN이고 B matrix의 크기가 NxK일때, C matrix의 크기는 MxK인 곱셈을 수행한다.&#xA;이 구현은 꽤 Naive한 구현이다. 이 구현에서 CUDA Kernel은 DRAM을 사용하여 각 thread가 A와 B의 행렬을 곱하는 방식으로 동작한다. 조금더 개선된 속도를 위해&#xA;shared memory를 사용하여 A와 B의 행렬을 곱하는 방식이 있다. 구현은 다음과 같다.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
