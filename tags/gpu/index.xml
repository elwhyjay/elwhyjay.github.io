<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GPU on Yongjun&#39;s blog</title>
    <link>http://localhost:1313/tags/gpu/</link>
    <description>Recent content in GPU on Yongjun&#39;s blog</description>
    <generator>Hugo</generator>
    <language>ko-kr</language>
    <lastBuildDate>Sat, 07 Feb 2026 00:35:33 +0900</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/gpu/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>FFT on GPU</title>
      <link>http://localhost:1313/post/fft/</link>
      <pubDate>Sat, 07 Feb 2026 00:35:33 +0900</pubDate>
      <guid>http://localhost:1313/post/fft/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&lt;p&gt;이 포스트에서 다룰것은 Fast fourier Transform이다. 이 알고리즘에대해서는 PS(Competitve programming) 하는 사람들은 익히 알것이다. 실제로 검색을해보면 알고리즘에 대해서는 상세히 알수가있다. 그렇기때문에 알고리즘을 톺아보기보다 GPU위에서 FFT를 구현하는것에대해 초점을 맞춰 글을 작성할 예정이다.&lt;/p&gt;&#xA;&lt;h1 id=&#34;background&#34;&gt;Background&lt;/h1&gt;&#xA;&lt;h2 id=&#34;fourier-transform&#34;&gt;Fourier Transform&lt;/h2&gt;&#xA;&lt;p&gt;Fourier Transform(푸리에 변환)은 신호를 주파수 성분으로 분해하는 수학적 기법이다. 이는 시간 도메인에서 표현된 신호를 주파수 도메인으로 변환하여, 신호의 주파수 특성을 분석하고 처리하는 데 사용된다. 푸리에 변환은 다양한 분야에서 활용되며, 특히 신호 처리, 이미지 처리, 음성 인식, 통신 시스템 등에서 중요한 역할을 한다. 정의는 이러한데 그렇다면 푸리에 변환은 이런 특정 도메인이 아니면 전혀 쓸모가 없는것일까? 익히 알려져있듯 이러한 도메인이아니라 일반적인 연산 영역에서도 푸리에 변환은 유용하게 사용될 수 있다. 이를 중점으로 살펴보자.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data_format</title>
      <link>http://localhost:1313/post/data_format/</link>
      <pubDate>Sun, 28 Dec 2025 21:59:14 +0900</pubDate>
      <guid>http://localhost:1313/post/data_format/</guid>
      <description>&lt;h1 id=&#34;현대-ai-데이터-타입-ml-엔지니어와-cuda-개발자를-위한-기술-심층-분석&#34;&gt;현대 AI 데이터 타입: ML 엔지니어와 CUDA 개발자를 위한 기술 심층 분석&lt;/h1&gt;&#xA;&lt;p&gt;저정밀도 수치 포맷은 효율적인 AI 추론의 핵심이 되었으며, &lt;strong&gt;FP8&lt;/strong&gt;은 Hopper GPU에서 &lt;strong&gt;2배의 처리량 증가&lt;/strong&gt;를 제공하면서 FP16에 가까운 정확도를 유지하고, &lt;strong&gt;INT4 가중치 전용(weight-only) 양자화&lt;/strong&gt;는 70B 파라미터 모델을 단일 48GB GPU에서 실행할 수 있게 해준다. 이 보고서는 15개 이상의 데이터 포맷에 대한 수학적 명세, 4세대 NVIDIA 아키텍처 전반에 걸친 하드웨어별 성능 특성, 그리고 양자화 알고리즘에 대한 정량적 분석을 제공한다. 이는 프로덕션 LLM 시스템을 배포하는 데 필수적인 지식이다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Int4 to FP16 dequantization optimization</title>
      <link>http://localhost:1313/post/int8tofloat16/</link>
      <pubDate>Tue, 02 Dec 2025 17:44:26 +0900</pubDate>
      <guid>http://localhost:1313/post/int8tofloat16/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Quantization은 현재 LLM 분야에서 중요한 기술로 자리잡았다. 특히 추론을 최적화하는데 있어서 가중치를 int4, int8 등의 저정밀도 정수형으로 양자화하는 기법이 널리 사용되고 있다. 이 기법을 통해 모델의 메모리 사용량을 줄이고, 메모리 대역폭 요구사항을 낮추며, 하드웨어 가속기의 연산 처리량을 극대화할 수 있다. 하지만 양자화 기술은 만능이 아니고 많은 경우에 최적화가 요구될 수 있다.&lt;/p&gt;&#xA;&lt;p&gt;이 글에서는 QServe에서 소개된 &lt;a href=&#34;https://arxiv.org/abs/2211.10017&#34;&gt;Kim et al.&lt;/a&gt; 의 논문에서 제시된 int4 양자화된 KV cache를 FP16 활성화 값으로 역양자화하는 비트 최적화 기법에 대해 살펴본다. 역양자화는 때로 과도한 연산량을 요구할 수 있기 때문에, 이를 효율적으로 처리하는 것이 중요하다. 이 최적화 기법은 computing resource를 절약하는 효과적인 방법중 하나로 이해하고 비슷한시나리오에서 사용가능할것 같다.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gpu_architec</title>
      <link>http://localhost:1313/post/gpu_architec/</link>
      <pubDate>Wed, 06 Aug 2025 12:22:45 +0900</pubDate>
      <guid>http://localhost:1313/post/gpu_architec/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;gpu programming을 하기위해서는 gpu architecture에 대한 이해가 필요하다. gpu가 무엇인지는 현재에와서는 모르는 사람이 없을것이다.&#xA;때문에 gpu에 대한 소개는 생략하고 gpu architecture를 곧바로 살펴보자&lt;/p&gt;&#xA;&lt;h2 id=&#34;gpu-hardware-architecture&#34;&gt;GPU Hardware Architecture&lt;/h2&gt;&#xA;&lt;p&gt;gpu architecture는 크게 다음과 같은 요소로 구성된다.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Streaming Multiprocessors (SMs)&lt;/strong&gt;: GPU의 핵심 컴퓨팅 유닛으로, 병렬 처리를 수행한다. 각 SM은 여러 개의 CUDA 코어를 포함하고 있으며, 동시에 여러 스레드를 실행할 수 있다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;HBM (High Bandwidth Memory)&lt;/strong&gt;: GPU의 글로벌 메모리로, 데이터 전송 속도가 매우 빠르다. HBM은 GPU와 CPU 간의 데이터 전송을 최적화하여 높은 성능을 제공한다. DRAM을 적층해 만든 구조로 CPU에서 DRAM의 역할과 유사하다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;L2 Cache&lt;/strong&gt;: GPU의 L2 캐시는 데이터 접근 속도를 높이기 위해 사용된다. L2 캐시는 GPU와 HBM 사이의 중간 캐시 역할을 하며, 자주 사용되는 데이터를 저장하여 빠른 접근을 가능하게 한다.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;NVLink&lt;/strong&gt;: 다른 GPU와의 연결을 위한 인터페이스로 , 다중 GPU 시스템에서 높은 대역폭을 제공한다. NVLink는 GPU 간의 데이터 전송 속도를 향상시켜, 병렬 처리 성능을 극대화한다.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;streaming-multiprocessors-sms&#34;&gt;Streaming Multiprocessors (SMs)&lt;/h3&gt;&#xA;&lt;p&gt;SMs는 GPU의 핵심 컴퓨팅 유닛으로, 병렬 처리를 수행한다. 각 SM은 다음과 같은 구성 요소로 이루어져 있다:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
